<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Webcam + Hand Tracking (MediaPipe Hands)</title>

  <!-- Google Fonts: Google Sans (Roboto as fallback) -->
  <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&display=swap" rel="stylesheet">

  <style>
    /* Root variables for dark/light mode */
    :root {
      --bg-color: #ffffff;
      --text-color: #111111;
      --card-bg: #f5f5f5;
      --button-bg: #1976d2;
      --button-color: #ffffff;
    }

    @media (prefers-color-scheme: dark) {
      :root {
        --bg-color: #121212;
        --text-color: #e0e0e0;
        --card-bg: #1e1e1e;
        --button-bg: #90caf9;
        --button-color: #121212;
      }
    }

    body {
      font-family: 'Google Sans', system-ui, Arial, sans-serif;
      margin: 16px;
      background-color: var(--bg-color);
      color: var(--text-color);
      transition: background-color 0.3s, color 0.3s;
    }

    h2, h3 {
      font-weight: 500;
    }

    .row {
      display: flex;
      gap: 16px;
      align-items: flex-start;
      flex-wrap: wrap;
      margin-top: 16px;
    }

    video, canvas {
      width: 640px;
      height: 480px;
      background: #111;
      border-radius: 8px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.2);
    }

    .input_video { display: none; }

    button {
      padding: 10px 16px;
      font-size: 14px;
      font-weight: 500;
      cursor: pointer;
      border: none;
      border-radius: 6px;
      background-color: var(--button-bg);
      color: var(--button-color);
      transition: background-color 0.2s, transform 0.1s;
    }

    button:hover {
      filter: brightness(1.1);
      transform: translateY(-1px);
    }

    button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }

    pre {
      background-color: var(--card-bg);
      padding: 12px;
      border-radius: 8px;
      white-space: pre-wrap;
      overflow-x: auto;
      max-width: 100%;
      box-shadow: inset 0 0 5px rgba(0,0,0,0.1);
      transition: background-color 0.3s, color 0.3s;
    }

    #status {
      font-weight: 500;
    }
  </style>

  <!-- MediaPipe libraries -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</head>

</head>
<body>
  <h2>Webcam + Hand Tracking (MediaPipe Hands)</h2>
  <p>Click <b>Start Camera</b>. If you see the hand skeleton, tracking works.</p>

  <button id="startBtn">Start Camera</button>
  <span id="status" style="margin-left:10px;">Status: idle</span>

  <div class="row" style="margin-top:16px;">
    <video class="input_video" playsinline></video>
    <canvas class="output_canvas" width="640" height="480"></canvas>
  </div>

  <h3>Debug</h3>
  <pre id="debug">No data yet.</pre>

  <script>
    const videoElement = document.querySelector(".input_video");
    const canvasElement = document.querySelector(".output_canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const startBtn = document.getElementById("startBtn");
    const statusEl = document.getElementById("status");
    const debugEl = document.getElementById("debug");

    let isRunning = false;

    // 1) Create the MediaPipe Hands model
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.5,
    });

    // 2) This runs every time MediaPipe finishes processing a frame
    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.translate(canvasElement.width, 0);
      canvasCtx.scale(-1, 1);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      // If a hand is found, draw landmarks + connectors
      const hasHand = results.multiHandLandmarks && results.multiHandLandmarks.length > 0;

      if (hasHand) {
        const handCount = results.multiHandLandmarks.length;
        const lines = [];

        for (let i = 0; i < handCount; i++) {
          const landmarks = results.multiHandLandmarks[i];
          const rawHandedness = results.multiHandedness?.[i]?.label ?? "Unknown";
          const handedness =
            rawHandedness === "Left"
              ? "Right"
              : rawHandedness === "Right"
              ? "Left"
              : rawHandedness;

          drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { lineWidth: 4 });
          drawLandmarks(canvasCtx, landmarks, { lineWidth: 2 });

          lines.push(
            `Hand ${i + 1}: ${handedness}`,
            `  Landmarks: ${landmarks.length} (should be 21)`,
            `  Wrist (0): x=${landmarks[0].x.toFixed(3)}, y=${landmarks[0].y.toFixed(3)}, z=${landmarks[0].z.toFixed(3)}`,
            `  Index Tip (8): x=${landmarks[8].x.toFixed(3)}, y=${landmarks[8].y.toFixed(3)}, z=${landmarks[8].z.toFixed(3)}`
          );
        }

        debugEl.textContent = lines.join("\n");
        statusEl.textContent = `Status: tracking (${handCount} hand${handCount > 1 ? "s" : ""} detected)`;
      } else {
        debugEl.textContent = "No hand detected. Put your hand in front of the camera.";
        statusEl.textContent = "Status: running (no hand)";
      }

      canvasCtx.restore();
    }

    hands.onResults(onResults);

    // 3) Create the camera helper: it pulls frames from the webcam and sends them to the model
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({ image: videoElement });
      },
      width: 640,
      height: 480,
    });

    // 4) Start button
    startBtn.addEventListener("click", async () => {
      if (isRunning) return;
      try {
        statusEl.textContent = "Status: requesting camera permission...";
        await camera.start();
        isRunning = true;
        startBtn.disabled = true;
        statusEl.textContent = "Status: running (show your hand)";
      } catch (err) {
        console.error(err);
        statusEl.textContent = "Status: camera failed";
        alert("Camera failed: " + (err?.message || err));
      }
    });
  </script>
</body>
</html>