var q = Object.defineProperty;
var K = (r, e, t) => e in r ? q(r, e, { enumerable: !0, configurable: !0, writable: !0, value: t }) : r[e] = t;
var l = (r, e, t) => K(r, typeof e != "symbol" ? e + "" : e, t);
var I;
const j = typeof process < "u" && ((I = process.env) != null && I.RF_API_BASE_URL) ? process.env.RF_API_BASE_URL : "https://api.roboflow.com", V = [
  "https://serverless.roboflow.com",
  "https://serverless.roboflow.one"
];
class b {
  /**
   * @private
   * Use InferenceHTTPClient.init() instead
   */
  constructor(e, t = "https://serverless.roboflow.com", n = j) {
    l(this, "apiKey");
    l(this, "serverUrl");
    l(this, "apiBaseUrl");
    this.apiKey = e, this.serverUrl = t, this.apiBaseUrl = n;
  }
  static init({ apiKey: e, serverUrl: t, apiBaseUrl: n }) {
    if (!e)
      throw new Error("apiKey is required");
    return new b(e, t, n);
  }
  /**
   * Initialize a WebRTC worker pipeline
   *
   * @param params - Pipeline parameters
   * @param params.offer - WebRTC offer { sdp, type }
   * @param params.workflowSpec - Workflow specification
   * @param params.config - Additional configuration
   * @param params.config.imageInputName - Input image name (default: "image")
   * @param params.config.streamOutputNames - Output stream names for video (default: [])
   * @param params.config.dataOutputNames - Output data names (default: ["string"])
   * @param params.config.threadPoolWorkers - Thread pool workers (default: 4)
   * @returns Promise resolving to answer with SDP and pipeline ID
   *
   * @example
   * ```typescript
   * const answer = await client.initializeWebrtcWorker({
   *   offer: { sdp, type },
   *   workflowSpec: { ... },
   *   config: {
   *     imageInputName: "image",
   *     streamOutputNames: ["output_image"]
   *   }
   * });
   * ```
   */
  async initializeWebrtcWorker({
    offer: e,
    workflowSpec: t,
    workspaceName: n,
    workflowId: a,
    config: o = {}
  }) {
    if (!e || !e.sdp || !e.type)
      throw new Error("offer with sdp and type is required");
    const i = !!t, f = !!(n && a);
    if (!i && !f)
      throw new Error("Either workflowSpec OR (workspaceName + workflowId) is required");
    if (i && f)
      throw new Error("Provide either workflowSpec OR (workspaceName + workflowId), not both");
    const {
      imageInputName: d = "image",
      streamOutputNames: c = [],
      dataOutputNames: s = [],
      threadPoolWorkers: y = 4,
      workflowsParameters: S = {},
      iceServers: p,
      processingTimeout: u,
      requestedPlan: h,
      requestedRegion: C,
      realtimeProcessing: E = !0,
      rtspUrl: R
    } = o, v = {
      type: "WorkflowConfiguration",
      image_input_name: d,
      workflows_parameters: S,
      workflows_thread_pool_workers: y,
      cancel_thread_pool_tasks_on_exit: !0,
      video_metadata_input_name: "video_metadata"
    };
    i ? v.workflow_specification = t : (v.workspace_name = n, v.workflow_id = a);
    const m = {
      workflow_configuration: v,
      api_key: this.apiKey,
      webrtc_realtime_processing: E,
      webrtc_offer: {
        sdp: e.sdp,
        type: e.type
      },
      webrtc_config: p ? { iceServers: p } : null,
      stream_output: c,
      data_output: s
    };
    u !== void 0 && (m.processing_timeout = u), h !== void 0 && (m.requested_plan = h), C !== void 0 && (m.requested_region = C), R && (m.rtsp_url = R);
    const w = await fetch(`${this.serverUrl}/initialise_webrtc_worker`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(m)
    });
    if (!w.ok) {
      const T = await w.text().catch(() => "");
      throw new Error(`initialise_webrtc_worker failed (${w.status}): ${T}`);
    }
    return await w.json();
  }
  async terminatePipeline({ pipelineId: e }) {
    if (!e)
      throw new Error("pipelineId is required");
    await fetch(
      `${this.serverUrl}/inference_pipelines/${e}/terminate?api_key=${this.apiKey}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" }
      }
    );
  }
  /**
   * Fetch TURN server configuration from Roboflow API
   *
   * This automatically fetches TURN server credentials for improved WebRTC
   * connectivity through firewalls and NAT. Only applicable when using
   * Roboflow serverless infrastructure.
   *
   * @returns Promise resolving to ICE server configuration, or null if not applicable
   *
   * @example
   * ```typescript
   * const client = InferenceHTTPClient.init({ apiKey: "your-api-key" });
   * const iceServers = await client.fetchTurnConfig();
   * // Returns: [{ urls: ["turn:..."], username: "...", credential: "..." }]
   * ```
   */
  async fetchTurnConfig() {
    if (!V.includes(this.serverUrl))
      return null;
    try {
      const e = await fetch(
        `${this.apiBaseUrl}/webrtc_turn_config?api_key=${this.apiKey}`,
        {
          method: "GET",
          headers: { "Content-Type": "application/json" }
        }
      );
      if (!e.ok)
        return console.warn(`[RFWebRTC] Failed to fetch TURN config (${e.status}), using defaults`), null;
      const t = await e.json();
      let n;
      if (Array.isArray(t))
        n = t;
      else if (t.iceServers && Array.isArray(t.iceServers))
        n = t.iceServers;
      else if (t.urls)
        n = [t];
      else
        return console.warn("[RFWebRTC] Invalid TURN config format, using defaults"), null;
      return n.map((o) => ({
        urls: Array.isArray(o.urls) ? o.urls : [o.urls],
        username: o.username,
        credential: o.credential
      }));
    } catch (e) {
      return console.warn("[RFWebRTC] Error fetching TURN config:", e), null;
    }
  }
}
const ie = {
  /**
   * Create a connector that uses API key directly
   *
   * **WARNING**: If you use this in the frontend, it will expose your API key. 
   * Use only for demos/testing.
   * For production, use withProxyUrl() with a backend proxy.
   *
   * @param apiKey - Roboflow API key
   * @param options - Additional options
   * @param options.serverUrl - Custom Roboflow server URL
   * @returns Connector with connectWrtc method
   *
   * @example
   * ```typescript
   * const connector = connectors.withApiKey("your-api-key");
   * const answer = await connector.connectWrtc(offer, wrtcParams);
   * ```
   */
  withApiKey(r, e = {}) {
    const { serverUrl: t, apiBaseUrl: n } = e;
    typeof window < "u" && console.warn(
      "[Security Warning] Using API key directly in browser will expose it. Use connectors.withProxyUrl() for production. See: https://docs.roboflow.com/api-reference/authentication#securing-your-api-key"
    );
    const a = b.init({ apiKey: r, serverUrl: t, apiBaseUrl: n });
    return {
      connectWrtc: async (o, i) => (console.debug("wrtcParams", i), await a.initializeWebrtcWorker({
        offer: o,
        workflowSpec: i.workflowSpec,
        workspaceName: i.workspaceName,
        workflowId: i.workflowId,
        config: {
          imageInputName: i.imageInputName,
          streamOutputNames: i.streamOutputNames,
          dataOutputNames: i.dataOutputNames,
          threadPoolWorkers: i.threadPoolWorkers,
          workflowsParameters: i.workflowsParameters,
          iceServers: i.iceServers,
          processingTimeout: i.processingTimeout,
          requestedPlan: i.requestedPlan,
          requestedRegion: i.requestedRegion,
          realtimeProcessing: i.realtimeProcessing,
          rtspUrl: i.rtspUrl
        }
      })),
      /**
       * Fetch TURN server configuration for improved WebRTC connectivity
       */
      getIceServers: async () => await a.fetchTurnConfig(),
      // Store apiKey for cleanup
      _apiKey: r,
      _serverUrl: t
    };
  },
  /**
   * Create a connector that uses a backend proxy (recommended for production)
   *
   * Your backend receives the offer and wrtcParams, adds the secret API key,
   * and forwards to Roboflow. This keeps your API key secure.
   *
   * For improved WebRTC connectivity through firewalls, implement a separate
   * endpoint for TURN server configuration that calls `fetchTurnConfig()`.
   *
   * @param proxyUrl - Backend proxy endpoint URL for WebRTC initialization
   * @param options - Additional options
   * @param options.turnConfigUrl - Optional URL for fetching TURN server configuration
   * @returns Connector with connectWrtc and optional getIceServers methods
   *
   * @example
   * ```typescript
   * // Frontend: Create connector with TURN config endpoint
   * const connector = connectors.withProxyUrl('/api/init-webrtc', {
   *   turnConfigUrl: '/api/turn-config'
   * });
   * ```
   *
   * @example
   * Backend implementation (Express) with TURN server support:
   * ```typescript
   * // Endpoint for TURN configuration (called first by SDK)
   * app.get('/api/turn-config', async (req, res) => {
   *   const client = InferenceHTTPClient.init({
   *     apiKey: process.env.ROBOFLOW_API_KEY
   *   });
   *   const iceServers = await client.fetchTurnConfig();
   *   res.json({ iceServers });
   * });
   *
   * // Endpoint for WebRTC initialization
   * app.post('/api/init-webrtc', async (req, res) => {
   *   const { offer, wrtcParams } = req.body;
   *   const client = InferenceHTTPClient.init({
   *     apiKey: process.env.ROBOFLOW_API_KEY
   *   });
   *
   *   const answer = await client.initializeWebrtcWorker({
   *     offer,
   *     workflowSpec: wrtcParams.workflowSpec,
   *     workspaceName: wrtcParams.workspaceName,
   *     workflowId: wrtcParams.workflowId,
   *     config: {
   *       imageInputName: wrtcParams.imageInputName,
   *       streamOutputNames: wrtcParams.streamOutputNames,
   *       dataOutputNames: wrtcParams.dataOutputNames,
   *       threadPoolWorkers: wrtcParams.threadPoolWorkers,
   *       workflowsParameters: wrtcParams.workflowsParameters,
   *       iceServers: wrtcParams.iceServers,
   *       processingTimeout: wrtcParams.processingTimeout,
   *       requestedPlan: wrtcParams.requestedPlan,
   *       requestedRegion: wrtcParams.requestedRegion
   *     }
   *   });
   *
   *   res.json(answer);
   * });
   * ```
   */
  withProxyUrl(r, e = {}) {
    const { turnConfigUrl: t } = e;
    return {
      connectWrtc: async (n, a) => {
        const o = await fetch(r, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            offer: n,
            wrtcParams: a
          })
        });
        if (!o.ok) {
          const i = await o.text().catch(() => "");
          throw new Error(`Proxy request failed (${o.status}): ${i}`);
        }
        return await o.json();
      },
      /**
       * Fetch TURN server configuration from the proxy backend
       * Only available if turnConfigUrl was provided
       */
      getIceServers: t ? async () => {
        try {
          const n = await fetch(t, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          return n.ok ? (await n.json()).iceServers || null : (console.warn(`[RFWebRTC] Failed to fetch TURN config from proxy (${n.status})`), null);
        } catch (n) {
          return console.warn("[RFWebRTC] Error fetching TURN config from proxy:", n), null;
        }
      } : void 0
    };
  }
};
async function $(r = { video: !0 }) {
  try {
    console.log("[RFStreams] requesting with", r);
    const e = await navigator.mediaDevices.getUserMedia(r);
    return console.log("[RFStreams] got stream", e.getVideoTracks().map((t) => ({ id: t.id, label: t.label }))), e;
  } catch (e) {
    console.warn("[RFStreams] failed, falling back", e);
    const t = await navigator.mediaDevices.getUserMedia({ video: !0, audio: !1 });
    return console.log("[RFStreams] fallback stream", t.getVideoTracks().map((n) => ({ id: n.id, label: n.label }))), t;
  }
}
function O(r) {
  r && (r.getTracks().forEach((e) => e.stop()), console.log("[RFStreams] Stream stopped"));
}
const oe = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({
  __proto__: null,
  stopStream: O,
  useCamera: $
}, Symbol.toStringTag, { value: "Module" })), k = 49152, M = 262144, z = 10;
function H(r) {
  return new Promise((e) => setTimeout(e, r));
}
class D {
  constructor(e, t) {
    l(this, "file");
    l(this, "channel");
    l(this, "totalChunks");
    l(this, "cancelled", !1);
    this.file = e, this.channel = t, this.totalChunks = Math.ceil(e.size / k);
  }
  /**
   * Cancel the upload
   */
  cancel() {
    this.cancelled = !0;
  }
  /**
   * Upload the file in chunks with backpressure handling
   *
   * @param onProgress - Optional callback for progress updates (bytesUploaded, totalBytes)
   */
  async upload(e) {
    const t = this.file.size;
    for (let n = 0; n < this.totalChunks; n++) {
      if (this.cancelled)
        throw new Error("Upload cancelled");
      if (this.channel.readyState !== "open")
        throw new Error("Video upload interrupted");
      const a = n * k, o = Math.min(a + k, t), i = this.file.slice(a, o), f = new Uint8Array(await i.arrayBuffer()), d = new ArrayBuffer(8 + f.length), c = new DataView(d);
      for (c.setUint32(0, n, !0), c.setUint32(4, this.totalChunks, !0), new Uint8Array(d, 8).set(f); this.channel.bufferedAmount > M; ) {
        if (this.channel.readyState !== "open")
          throw new Error("Video upload interrupted");
        await H(z);
      }
      this.channel.send(d), e && e(o, t);
    }
  }
}
const J = 12;
class N {
  constructor() {
    l(this, "pendingFrames", /* @__PURE__ */ new Map());
  }
  /**
   * Process an incoming chunk and return the complete message if all chunks received
   */
  processChunk(e, t, n, a) {
    if (n === 1)
      return a;
    this.pendingFrames.has(e) || this.pendingFrames.set(e, {
      chunks: /* @__PURE__ */ new Map(),
      totalChunks: n
    });
    const o = this.pendingFrames.get(e);
    if (o.chunks.set(t, a), o.chunks.size === n) {
      const i = Array.from(o.chunks.values()).reduce((c, s) => c + s.length, 0), f = new Uint8Array(i);
      let d = 0;
      for (let c = 0; c < n; c++) {
        const s = o.chunks.get(c);
        f.set(s, d), d += s.length;
      }
      return this.pendingFrames.delete(e), f;
    }
    return null;
  }
  /**
   * Clear all pending frames (for cleanup)
   */
  clear() {
    this.pendingFrames.clear();
  }
}
function A(r) {
  const e = new DataView(r), t = e.getUint32(0, !0), n = e.getUint32(4, !0), a = e.getUint32(8, !0), o = new Uint8Array(r, J);
  return { frameId: t, chunkIndex: n, totalChunks: a, payload: o };
}
async function G(r, e = 6e3) {
  if (r.iceGatheringState === "complete") return;
  let t = !1;
  const n = (a) => {
    a.candidate && a.candidate.type === "srflx" && (t = !0);
  };
  r.addEventListener("icecandidate", n);
  try {
    await Promise.race([
      new Promise((a) => {
        const o = () => {
          r.iceGatheringState === "complete" && (r.removeEventListener("icegatheringstatechange", o), a());
        };
        r.addEventListener("icegatheringstatechange", o);
      }),
      new Promise((a, o) => {
        setTimeout(() => {
          t ? a() : (console.error("[ICE] timeout with NO srflx candidate! Connection may fail."), o(new Error("ICE gathering timeout without srflx candidate")));
        }, e);
      })
    ]);
  } finally {
    r.removeEventListener("icecandidate", n);
  }
}
function Z(r) {
  return new Promise((e) => {
    r.addEventListener("track", (t) => {
      t.streams && t.streams[0] && e(t.streams[0]);
    });
  });
}
const Q = [
  { urls: ["stun:stun.l.google.com:19302"] }
];
async function X(r, e, t, n, a) {
  if ([!!r, !!e, !!n].filter(Boolean).length !== 1)
    throw new Error("Exactly one of localStream, file, or rtspUrl must be provided");
  const c = t ?? Q, s = new RTCPeerConnection({
    iceServers: c
  });
  a != null && a.onPeerConnectionCreated && await a.onPeerConnectionCreated(s);
  try {
    s.addTransceiver("video", { direction: "recvonly" });
  } catch (h) {
    console.warn("[RFWebRTC] Could not add transceiver:", h);
  }
  if (r)
    for (const h of r.getVideoTracks()) {
      const C = s.addTrack(h, r);
      a != null && a.onTrackAdded && await a.onTrackAdded(h, C, s);
    }
  const y = Z(s), S = s.createDataChannel("inference", {
    ordered: !0
  });
  let p;
  e && (p = s.createDataChannel("video_upload"));
  let u = await s.createOffer();
  if (a != null && a.onOfferCreated) {
    const h = await a.onOfferCreated(u);
    h && (u = h);
  }
  return await s.setLocalDescription(u), await G(s), {
    pc: s,
    offer: s.localDescription,
    remoteStreamPromise: y,
    dataChannel: S,
    uploadChannel: p
  };
}
async function Y(r) {
  const e = r.getSenders().find((n) => n.track && n.track.kind === "video");
  if (!e) return;
  const t = e.getParameters();
  t.encodings = t.encodings || [{}], t.encodings[0].scaleResolutionDownBy = 1;
  try {
    await e.setParameters(t);
  } catch (n) {
    console.warn("[RFWebRTC] Failed to set encoding parameters:", n);
  }
}
function ee(r, e = 3e4) {
  return new Promise((t, n) => {
    if (r.readyState === "open") {
      t();
      return;
    }
    const a = () => {
      r.removeEventListener("open", a), r.removeEventListener("error", o), clearTimeout(i), t();
    }, o = () => {
      r.removeEventListener("open", a), r.removeEventListener("error", o), clearTimeout(i), n(new Error("Datachannel error"));
    }, i = setTimeout(() => {
      r.removeEventListener("open", a), r.removeEventListener("error", o), n(new Error("Datachannel open timeout"));
    }, e);
    r.addEventListener("open", a), r.addEventListener("error", o);
  });
}
class x {
  /** @private */
  constructor(e, t, n, a, o, i) {
    /**
     * The underlying RTCPeerConnection.
     * Exposed for advanced use cases like getting stats or accessing senders.
     */
    l(this, "peerConnection");
    l(this, "_localStream");
    l(this, "remoteStreamPromise");
    l(this, "pipelineId");
    l(this, "apiKey");
    /**
     * The data channel used for receiving inference results.
     * Exposed for advanced use cases.
     */
    l(this, "dataChannel");
    l(this, "reassembler");
    l(this, "ackPacingEnabled");
    /**
     * The data channel used for uploading video files (only available in file upload mode).
     * Exposed for advanced use cases.
     */
    l(this, "uploadChannel");
    l(this, "uploader");
    l(this, "onComplete");
    this.peerConnection = e, this._localStream = i == null ? void 0 : i.localStream, this.remoteStreamPromise = t, this.pipelineId = n, this.apiKey = a, this.dataChannel = o, this.reassembler = new N(), this.ackPacingEnabled = (i == null ? void 0 : i.ackPacingEnabled) === !0, this.uploadChannel = i == null ? void 0 : i.uploadChannel, this.onComplete = i == null ? void 0 : i.onComplete, this.dataChannel.binaryType = "arraybuffer";
    const f = i == null ? void 0 : i.onData;
    f && (this.dataChannel.addEventListener("message", (d) => {
      try {
        if (d.data instanceof ArrayBuffer) {
          const { frameId: c, chunkIndex: s, totalChunks: y, payload: S } = A(d.data), p = this.reassembler.processChunk(c, s, y, S);
          if (p) {
            const h = new TextDecoder("utf-8").decode(p), C = JSON.parse(h);
            Promise.resolve(f(C)).finally(() => {
              this.maybeSendAck(c);
            });
          }
        } else {
          const c = JSON.parse(d.data);
          f(c);
        }
      } catch (c) {
        console.error("[RFWebRTC] Failed to parse data channel message:", c);
      }
    }), this.dataChannel.addEventListener("error", (d) => {
      console.error("[RFWebRTC] Data channel error:", d);
    })), this.dataChannel.addEventListener("close", () => {
      this.reassembler.clear(), this.onComplete && this.onComplete();
    });
  }
  /**
   * Send cumulative ACK after a frame is fully handled.
   * Only used in batch mode (realtimeProcessing=false).
   */
  maybeSendAck(e) {
    this.ackPacingEnabled && this.dataChannel.readyState === "open" && this.dataChannel.send(JSON.stringify({ ack: e }));
  }
  /**
   * Get the remote stream (processed video from Roboflow)
   *
   * @returns Promise resolving to the remote MediaStream
   *
   * @example
   * ```typescript
   * const conn = await useStream({ ... });
   * const remoteStream = await conn.remoteStream();
   * videoElement.srcObject = remoteStream;
   * ```
   */
  async remoteStream() {
    return await this.remoteStreamPromise;
  }
  /**
   * Get the local stream (original camera)
   *
   * @returns The local MediaStream, or undefined if using file upload mode
   *
   * @example
   * ```typescript
   * const conn = await useStream({ ... });
   * const localStream = conn.localStream();
   * if (localStream) {
   *   videoElement.srcObject = localStream;
   * }
   * ```
   */
  localStream() {
    return this._localStream;
  }
  /**
   * Cleanup and close connection
   *
   * Terminates the pipeline on Roboflow, closes the peer connection,
   * and stops the local media stream (if applicable).
   *
   * @returns Promise that resolves when cleanup is complete
   *
   * @example
   * ```typescript
   * const conn = await useStream({ ... });
   * // ... use connection ...
   * await conn.cleanup(); // Clean up when done
   * ```
   */
  async cleanup() {
    if (this.uploader && this.uploader.cancel(), this.reassembler.clear(), this.pipelineId && this.apiKey)
      try {
        await b.init({ apiKey: this.apiKey }).terminatePipeline({ pipelineId: this.pipelineId });
      } catch (e) {
        console.warn("[RFWebRTC] Failed to terminate pipeline:", e);
      }
    this.peerConnection && this.peerConnection.connectionState !== "closed" && this.peerConnection.close(), this._localStream && O(this._localStream);
  }
  /**
   * Start uploading a file through the connection
   *
   * @param file - The file to upload
   * @param onProgress - Optional callback for progress updates (bytesUploaded, totalBytes)
   * @returns Promise that resolves when upload is complete
   * @throws Error if no upload channel is available
   *
   * @example
   * ```typescript
   * await connection.startUpload(videoFile, (uploaded, total) => {
   *   console.log(`Upload progress: ${(uploaded / total * 100).toFixed(1)}%`);
   * });
   * ```
   */
  async startUpload(e, t) {
    if (!this.uploadChannel)
      throw new Error("No upload channel available. This connection was not created for file uploads.");
    await ee(this.uploadChannel), this.uploader = new D(e, this.uploadChannel), await this.uploader.upload(t);
  }
  /**
   * Cancel any ongoing file upload
   */
  cancelUpload() {
    this.uploader && this.uploader.cancel();
  }
  /**
   * Reconfigure pipeline outputs at runtime
   *
   * Dynamically change stream and data outputs without restarting the connection.
   * Set a field to `null` to leave it unchanged, or to `null` value to enable all outputs,
   * or to `[]` to disable/auto-detect.
   *
   * @param config - Output configuration
   * @param config.streamOutput - Stream output names (null = unchanged, [] = auto-detect, ["name"] = specific output)
   * @param config.dataOutput - Data output names (null = unchanged, [] = disable, ["name"] = specific outputs, null value = all outputs)
   *
   * @example
   * ```typescript
   * // Change to different stream output
   * connection.reconfigureOutputs({
   *   streamOutput: ["annotated_image"],
   *   dataOutput: null  // unchanged
   * });
   *
   * // Enable all data outputs
   * connection.reconfigureOutputs({
   *   streamOutput: null,  // unchanged
   *   dataOutput: null     // null value = all outputs
   * });
   *
   * // Disable all data outputs
   * connection.reconfigureOutputs({
   *   streamOutput: null,  // unchanged
   *   dataOutput: []       // empty array = disable
   * });
   * ```
   */
  reconfigureOutputs(e) {
    const t = {};
    e.streamOutput !== void 0 && (t.stream_output = e.streamOutput), e.dataOutput !== void 0 && (t.data_output = e.dataOutput), this.sendData(t);
  }
  /**
   * Send data through the data channel
   * @private
   */
  sendData(e) {
    if (this.dataChannel.readyState !== "open") {
      console.warn("[RFWebRTC] Data channel is not open. Current state:", this.dataChannel.readyState);
      return;
    }
    try {
      const t = typeof e == "string" ? e : JSON.stringify(e);
      this.dataChannel.send(t);
    } catch (t) {
      console.error("[RFWebRTC] Failed to send data:", t);
    }
  }
}
async function F({
  source: r,
  rtspUrl: e,
  connector: t,
  wrtcParams: n,
  onData: a,
  onComplete: o,
  onFileUploadProgress: i,
  options: f = {},
  hooks: d
}) {
  var W;
  if (!t || typeof t.connectWrtc != "function")
    throw new Error("connector must have a connectWrtc method");
  const c = !!e, s = !c && r instanceof File, y = !c && !s && r ? r : void 0, S = s ? r : void 0;
  let p = n.iceServers;
  if ((!p || p.length === 0) && t.getIceServers)
    try {
      const g = await t.getIceServers();
      g && g.length > 0 && (p = g, console.log("[RFWebRTC] Using TURN servers from connector"));
    } catch (g) {
      console.warn("[RFWebRTC] Failed to fetch TURN config, using defaults:", g);
    }
  const { pc: u, offer: h, remoteStreamPromise: C, dataChannel: E, uploadChannel: R } = await X(
    y,
    S,
    p,
    e,
    d
  ), v = {
    ...n,
    iceServers: p,
    realtimeProcessing: n.realtimeProcessing ?? !s,
    rtspUrl: e
  }, m = await t.connectWrtc(
    { sdp: h.sdp, type: h.type },
    v
  ), w = { sdp: m.sdp, type: m.type };
  if (!(w != null && w.sdp) || !(w != null && w.type))
    throw console.error("[RFWebRTC] Invalid answer from server:", m), new Error("connector.connectWrtc must return answer with sdp and type");
  const U = ((W = m == null ? void 0 : m.context) == null ? void 0 : W.pipeline_id) || null;
  await u.setRemoteDescription(w), await new Promise((g, L) => {
    const _ = () => {
      u.connectionState === "connected" ? (u.removeEventListener("connectionstatechange", _), g()) : u.connectionState === "failed" && (u.removeEventListener("connectionstatechange", _), L(new Error("WebRTC connection failed")));
    };
    u.addEventListener("connectionstatechange", _), _(), setTimeout(() => {
      u.removeEventListener("connectionstatechange", _), L(new Error("WebRTC connection timeout after 30s"));
    }, 3e4);
  }), y && f.disableInputStreamDownscaling !== !1 && await Y(u);
  const T = t._apiKey || null, B = v.realtimeProcessing === !1, P = new x(
    u,
    C,
    U,
    T,
    E,
    {
      localStream: y,
      uploadChannel: R,
      onData: a,
      onComplete: o,
      ackPacingEnabled: B
    }
  );
  return S && R && P.startUpload(S, i).catch((g) => {
    console.error("[RFWebRTC] Upload error:", g);
  }), P;
}
async function te({
  source: r,
  connector: e,
  wrtcParams: t,
  onData: n,
  options: a = {},
  hooks: o
}) {
  if (r instanceof File)
    throw new Error("useStream requires a MediaStream. Use useVideoFile for File uploads.");
  return F({
    source: r,
    connector: e,
    wrtcParams: t,
    onData: n,
    options: a,
    hooks: o
  });
}
async function re({
  file: r,
  connector: e,
  wrtcParams: t,
  onData: n,
  onUploadProgress: a,
  onComplete: o,
  hooks: i
}) {
  return F({
    source: r,
    connector: e,
    wrtcParams: {
      ...t,
      realtimeProcessing: t.realtimeProcessing ?? !0
    },
    onData: n,
    onComplete: o,
    onFileUploadProgress: a,
    hooks: i
  });
}
async function ne({
  rtspUrl: r,
  connector: e,
  wrtcParams: t,
  onData: n,
  hooks: a
}) {
  if (!r.startsWith("rtsp://") && !r.startsWith("rtsps://"))
    throw new Error("Invalid RTSP URL: must start with rtsp:// or rtsps://");
  return F({
    rtspUrl: r,
    connector: e,
    wrtcParams: t,
    onData: n,
    hooks: a
  });
}
const se = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({
  __proto__: null,
  ChunkReassembler: N,
  FileUploader: D,
  RFWebRTCConnection: x,
  parseBinaryHeader: A,
  useRtspStream: ne,
  useStream: te,
  useVideoFile: re
}, Symbol.toStringTag, { value: "Module" }));
export {
  b as InferenceHTTPClient,
  ie as connectors,
  oe as streams,
  se as webrtc
};
//# sourceMappingURL=index.es.js.map
