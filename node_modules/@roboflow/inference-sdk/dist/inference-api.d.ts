export interface WebRTCWorkerConfig {
    imageInputName?: string;
    streamOutputNames?: string[];
    dataOutputNames?: string[];
    threadPoolWorkers?: number;
    /**
     * Workflow parameters to pass to the workflow execution
     */
    workflowsParameters?: Record<string, any>;
    /**
     * ICE servers for WebRTC connections (used for both client and server)
     */
    iceServers?: RTCIceServerConfig[];
    /**
     * Processing timeout in seconds (serverless only)
     * @default 600
     */
    processingTimeout?: number;
    /**
     * Requested compute plan (serverless only)
     * @example "webrtc-gpu-small"
     */
    requestedPlan?: string;
    /**
     * Requested region for processing (serverless only)
     * @example "us"
     */
    requestedRegion?: string;
    /**
     * Set to false for file upload mode (batch processing).
     * When false, server processes all frames sequentially instead of dropping frames.
     * @default true
     */
    realtimeProcessing?: boolean;
    /**
     * RTSP URL for server-side video capture.
     * When provided, the server captures video from this RTSP stream instead of receiving
     * video from the client. Supports credentials in URL format: rtsp://user:pass@host/stream
     * @example "rtsp://camera.local/stream"
     */
    rtspUrl?: string;
}
/**
 * ICE server configuration for WebRTC connections
 *
 * Use this to configure custom STUN/TURN servers for users behind
 * symmetric NAT or restrictive firewalls.
 */
export interface RTCIceServerConfig {
    urls: string[];
    username?: string;
    credential?: string;
}
export interface WebRTCOffer {
    sdp: string;
    type: string;
}
export type WorkflowSpec = Record<string, any>;
export interface WebRTCWorkerResponse {
    status?: string;
    sdp: string;
    type: string;
    context?: {
        request_id: string | null;
        pipeline_id: string | null;
    };
}
export interface WebRTCParams {
    workflowSpec?: WorkflowSpec;
    workspaceName?: string;
    workflowId?: string;
    imageInputName?: string;
    streamOutputNames?: string[];
    dataOutputNames?: string[];
    threadPoolWorkers?: number;
    /**
     * Workflow parameters to pass to the workflow execution
     */
    workflowsParameters?: Record<string, any>;
    /**
     * ICE servers for WebRTC connections (used for both client and server)
     *
     * Use this to specify custom STUN/TURN servers for users behind
     * symmetric NAT or restrictive firewalls. The same configuration is
     * used for both the client-side RTCPeerConnection and sent to the
     * server via webrtc_config.
     *
     * @example
     * ```typescript
     * iceServers: [
     *   { urls: ["stun:stun.l.google.com:19302"] },
     *   { urls: ["turn:turn.example.com:3478"], username: "user", credential: "pass" }
     * ]
     * ```
     */
    iceServers?: RTCIceServerConfig[];
    /**
     * Processing timeout in seconds (serverless only)
     * @default 600
     */
    processingTimeout?: number;
    /**
     * Requested compute plan (serverless only)
     * @example "webrtc-gpu-small"
     */
    requestedPlan?: string;
    /**
     * Requested region for processing (serverless only)
     * @example "us"
     */
    requestedRegion?: string;
    /**
     * Set to false for file upload mode (batch processing).
     * When false, server processes all frames sequentially instead of dropping frames.
     * @default true
     */
    realtimeProcessing?: boolean;
    /**
     * RTSP URL for server-side video capture.
     * When provided, the server captures video from this RTSP stream instead of receiving
     * video from the client. Supports credentials in URL format: rtsp://user:pass@host/stream
     * @example "rtsp://camera.local/stream"
     */
    rtspUrl?: string;
}
export interface Connector {
    connectWrtc(offer: WebRTCOffer, wrtcParams: WebRTCParams): Promise<WebRTCWorkerResponse>;
    /**
     * Fetch ICE servers (TURN configuration) for WebRTC connections
     * This should be called BEFORE creating the RTCPeerConnection to ensure
     * proper NAT traversal configuration.
     *
     * @returns Promise resolving to ICE server configuration, or null/undefined if not available
     */
    getIceServers?(): Promise<RTCIceServerConfig[] | null>;
    _apiKey?: string;
    _serverUrl?: string;
}
export declare class InferenceHTTPClient {
    private apiKey;
    private serverUrl;
    private apiBaseUrl;
    /**
     * @private
     * Use InferenceHTTPClient.init() instead
     */
    private constructor();
    static init({ apiKey, serverUrl, apiBaseUrl }: {
        apiKey: string;
        serverUrl?: string;
        apiBaseUrl?: string;
    }): InferenceHTTPClient;
    /**
     * Initialize a WebRTC worker pipeline
     *
     * @param params - Pipeline parameters
     * @param params.offer - WebRTC offer { sdp, type }
     * @param params.workflowSpec - Workflow specification
     * @param params.config - Additional configuration
     * @param params.config.imageInputName - Input image name (default: "image")
     * @param params.config.streamOutputNames - Output stream names for video (default: [])
     * @param params.config.dataOutputNames - Output data names (default: ["string"])
     * @param params.config.threadPoolWorkers - Thread pool workers (default: 4)
     * @returns Promise resolving to answer with SDP and pipeline ID
     *
     * @example
     * ```typescript
     * const answer = await client.initializeWebrtcWorker({
     *   offer: { sdp, type },
     *   workflowSpec: { ... },
     *   config: {
     *     imageInputName: "image",
     *     streamOutputNames: ["output_image"]
     *   }
     * });
     * ```
     */
    initializeWebrtcWorker({ offer, workflowSpec, workspaceName, workflowId, config }: {
        offer: WebRTCOffer;
        workflowSpec?: WorkflowSpec;
        workspaceName?: string;
        workflowId?: string;
        config?: WebRTCWorkerConfig;
    }): Promise<WebRTCWorkerResponse>;
    terminatePipeline({ pipelineId }: {
        pipelineId: string;
    }): Promise<void>;
    /**
     * Fetch TURN server configuration from Roboflow API
     *
     * This automatically fetches TURN server credentials for improved WebRTC
     * connectivity through firewalls and NAT. Only applicable when using
     * Roboflow serverless infrastructure.
     *
     * @returns Promise resolving to ICE server configuration, or null if not applicable
     *
     * @example
     * ```typescript
     * const client = InferenceHTTPClient.init({ apiKey: "your-api-key" });
     * const iceServers = await client.fetchTurnConfig();
     * // Returns: [{ urls: ["turn:..."], username: "...", credential: "..." }]
     * ```
     */
    fetchTurnConfig(): Promise<RTCIceServerConfig[] | null>;
}
/**
 * Connectors for establishing WebRTC connections to Roboflow
 */
export declare const connectors: {
    /**
     * Create a connector that uses API key directly
     *
     * **WARNING**: If you use this in the frontend, it will expose your API key.
     * Use only for demos/testing.
     * For production, use withProxyUrl() with a backend proxy.
     *
     * @param apiKey - Roboflow API key
     * @param options - Additional options
     * @param options.serverUrl - Custom Roboflow server URL
     * @returns Connector with connectWrtc method
     *
     * @example
     * ```typescript
     * const connector = connectors.withApiKey("your-api-key");
     * const answer = await connector.connectWrtc(offer, wrtcParams);
     * ```
     */
    withApiKey(apiKey: string, options?: {
        serverUrl?: string;
        apiBaseUrl?: string;
    }): Connector;
    /**
     * Create a connector that uses a backend proxy (recommended for production)
     *
     * Your backend receives the offer and wrtcParams, adds the secret API key,
     * and forwards to Roboflow. This keeps your API key secure.
     *
     * For improved WebRTC connectivity through firewalls, implement a separate
     * endpoint for TURN server configuration that calls `fetchTurnConfig()`.
     *
     * @param proxyUrl - Backend proxy endpoint URL for WebRTC initialization
     * @param options - Additional options
     * @param options.turnConfigUrl - Optional URL for fetching TURN server configuration
     * @returns Connector with connectWrtc and optional getIceServers methods
     *
     * @example
     * ```typescript
     * // Frontend: Create connector with TURN config endpoint
     * const connector = connectors.withProxyUrl('/api/init-webrtc', {
     *   turnConfigUrl: '/api/turn-config'
     * });
     * ```
     *
     * @example
     * Backend implementation (Express) with TURN server support:
     * ```typescript
     * // Endpoint for TURN configuration (called first by SDK)
     * app.get('/api/turn-config', async (req, res) => {
     *   const client = InferenceHTTPClient.init({
     *     apiKey: process.env.ROBOFLOW_API_KEY
     *   });
     *   const iceServers = await client.fetchTurnConfig();
     *   res.json({ iceServers });
     * });
     *
     * // Endpoint for WebRTC initialization
     * app.post('/api/init-webrtc', async (req, res) => {
     *   const { offer, wrtcParams } = req.body;
     *   const client = InferenceHTTPClient.init({
     *     apiKey: process.env.ROBOFLOW_API_KEY
     *   });
     *
     *   const answer = await client.initializeWebrtcWorker({
     *     offer,
     *     workflowSpec: wrtcParams.workflowSpec,
     *     workspaceName: wrtcParams.workspaceName,
     *     workflowId: wrtcParams.workflowId,
     *     config: {
     *       imageInputName: wrtcParams.imageInputName,
     *       streamOutputNames: wrtcParams.streamOutputNames,
     *       dataOutputNames: wrtcParams.dataOutputNames,
     *       threadPoolWorkers: wrtcParams.threadPoolWorkers,
     *       workflowsParameters: wrtcParams.workflowsParameters,
     *       iceServers: wrtcParams.iceServers,
     *       processingTimeout: wrtcParams.processingTimeout,
     *       requestedPlan: wrtcParams.requestedPlan,
     *       requestedRegion: wrtcParams.requestedRegion
     *     }
     *   });
     *
     *   res.json(answer);
     * });
     * ```
     */
    withProxyUrl(proxyUrl: string, options?: {
        turnConfigUrl?: string;
    }): Connector;
};
//# sourceMappingURL=inference-api.d.ts.map